{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_evaluation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "57SCOcInULbj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifier Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "3sZdLALtSf_i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Topics**\n",
        "*  Motivation for model evaluation\n",
        "*  Model evaluation procedure\n",
        "*  Model evaluation metrics:\n",
        " *  Accuracy\n",
        " *  Confusion matrix\n",
        " *  Precision, Recall, F1\n",
        " *  Receiver Operating Characteristic (ROC) Curves\n",
        " *  Area Under the Curve (AUC)\n",
        "\n",
        "\n",
        "*This tutorial is derived from Data School's Machine Learning with scikit-learn tutorial. *"
      ]
    },
    {
      "metadata": {
        "id": "oBz9FrOZTAv2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Why are we already talking about model evaluation?**\n",
        "\n",
        " *   We need a way to choose between different model types, tuning parameters, and features\n",
        " *   Model evaluation enables us to estimate how well a model will generalize to out-of-sample data\n",
        " *   A model evaluation metric (or many!) required to quantify the model performance\n"
      ]
    },
    {
      "metadata": {
        "id": "fwJVWtTVTWbz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Model evaluation procedure:**\n",
        "1. Split the dataset into a TRAINING set and TESTING set.  Put the testing data set aside and do not use it for any part of model training.\n",
        "2. Leave out part of the TRAINING set as a VALIDATION set.\n",
        "3. Train the model on only the TRAINING data set.\n",
        "4. Evaluate model performance on the VALIDATION set.\n",
        "5. Repeat steps 2+ as necessary.\n",
        "6. Only once the model has been finalized, should you evaluate on the left-out TESTING set."
      ]
    },
    {
      "metadata": {
        "id": "QoU7RS38TWmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Classification Data Set**\n",
        "In this notebook we will work with the popular [PIMA Indians diabetes dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database/version/1). The goal is to predict whether or not a given female patient will contract diabetes based on certain diagnostic measurements. This is a ***binary*** classification problem. An outcome value of 0 indicates that the patient does not have diabetes, while an outcome of 1 indicates that the patient does have diabetes. \n",
        "\n",
        "(Note: We will not discuss regression evaluation in this notebook, but feel free to ask!)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ym-sI1JMfPT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "abea4f8a-9a89-455f-a891-dc4e52e2dadd"
      },
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "!pip install graphviz \n",
        "!apt-get install graphviz\n",
        "\n",
        "import graphviz \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.8.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.38.0-16ubuntu2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bX7xCiaESvv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebc94a59-eb82-4bef-e9fe-90c44afa6729"
      },
      "cell_type": "code",
      "source": [
        "# Read in the data\n",
        "data_url = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/diabetes.csv'\n",
        "data = pd.read_csv(data_url)\n",
        "data.head()\n",
        "data[\"Pregnancies\"].max()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "u5SL40nidJrz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The columns correspond to the following features:\n",
        "*  **Pregnancies:** Number of times pregnant\n",
        "* **Glucose: ** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "* **BloodPressure: ** Diastolic blood pressure (mm Hg)\n",
        "* **SkinThickness: ** Triceps skin fold thickness (mm)\n",
        "* **Insulin: ** 2-Hour serum insulin (mu U/ml)\n",
        "* **BMI: ** Body mass index (weight in kg/(height in m)^2)\n",
        "* **DiabetesPedigreeFunction: ** Diabetes pedigree function\n",
        "* **Age: ** Age (years)\n",
        "* **Outcome: ** Whether or not the woman has diabetes (0 or 1)"
      ]
    },
    {
      "metadata": {
        "id": "zJPvQo9kdgKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "29e3f4f6-cb36-4dc8-8111-8e7d739d5ec2"
      },
      "cell_type": "code",
      "source": [
        "# define features (X) and labels (y)\n",
        "feature_names = ['Pregnancies','Glucose','BloodPressure','SkinThickness','BMI','Age']\n",
        "X = data.loc[:, feature_names]\n",
        "y = data.Outcome\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>33.6</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>26.6</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>28.1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>43.1</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness   BMI  Age\n",
              "0            6      148             72             35  33.6   50\n",
              "1            1       85             66             29  26.6   31\n",
              "2            8      183             64              0  23.3   32\n",
              "3            1       89             66             23  28.1   21\n",
              "4            0      137             40             35  43.1   33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "UeWjHRSd6HhQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split the data set into training, validation, and test sets"
      ]
    },
    {
      "metadata": {
        "id": "2jJdDuQystTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d392e29b-dce4-4422-d4d2-476564d19ebe"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split X and y into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# further split X and y into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kYzKhOU36Ms9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train a model on the training data only"
      ]
    },
    {
      "metadata": {
        "id": "8-x6Uhcas3kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "173624bd-a8b7-4eb5-90ff-140e83b10cef"
      },
      "cell_type": "code",
      "source": [
        "# train a logistic regression model on the training set\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# instantiate model\n",
        "model = DecisionTreeClassifier(max_depth=4,random_state=0)\n",
        "\n",
        "# fit model\n",
        "model.fit(X_train, y_train)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
              "            splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "FEr2Zey7tREn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "7ccd3cd8-d261-4856-da2f-2e9438c1fd71"
      },
      "cell_type": "code",
      "source": [
        "# visualize the decision tree\n",
        "dot_data = tree.export_graphviz(model, out_file=None, \n",
        "                         feature_names=feature_names,  \n",
        "                         class_names=['No Diabetes','Diabetes'],  \n",
        "                         filled=True, rounded=True,\n",
        "                         max_depth=1) \n",
        "\n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f717c7e59e8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"333pt\" height=\"282pt\"\n viewBox=\"0.00 0.00 332.50 282.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 278)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-278 328.5,-278 328.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\"><title>0</title>\n<path fill=\"#e58139\" fill-opacity=\"0.462745\" stroke=\"black\" d=\"M233,-274C233,-274 96,-274 96,-274 90,-274 84,-268 84,-262 84,-262 84,-203 84,-203 84,-197 90,-191 96,-191 96,-191 233,-191 233,-191 239,-191 245,-197 245,-203 245,-203 245,-262 245,-262 245,-268 239,-274 233,-274\"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Glucose &lt;= 123.5</text>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.455</text>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 432</text>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [281, 151]</text>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Diabetes</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\"><title>1</title>\n<path fill=\"#e58139\" fill-opacity=\"0.776471\" stroke=\"black\" d=\"M149,-155C149,-155 12,-155 12,-155 6,-155 0,-149 0,-143 0,-143 0,-84 0,-84 0,-78 6,-72 12,-72 12,-72 149,-72 149,-72 155,-72 161,-78 161,-84 161,-84 161,-143 161,-143 161,-149 155,-155 149,-155\"/>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">BMI &lt;= 26.9</text>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.3</text>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 245</text>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [200, 45]</text>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Diabetes</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M135.357,-190.907C128.971,-182.014 122.148,-172.509 115.558,-163.331\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"118.267,-161.103 109.592,-155.021 112.581,-165.185 118.267,-161.103\"/>\n<text text-anchor=\"middle\" x=\"105.542\" y=\"-175.991\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node5\" class=\"node\"><title>10</title>\n<path fill=\"#399de5\" fill-opacity=\"0.235294\" stroke=\"black\" d=\"M308,-155C308,-155 191,-155 191,-155 185,-155 179,-149 179,-143 179,-143 179,-84 179,-84 179,-78 185,-72 191,-72 191,-72 308,-72 308,-72 314,-72 320,-78 320,-84 320,-84 320,-143 320,-143 320,-149 314,-155 308,-155\"/>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">BMI &lt;= 30.05</text>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.491</text>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 187</text>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [81, 106]</text>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Diabetes</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M193.99,-190.907C200.451,-182.014 207.357,-172.509 214.024,-163.331\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"217.016,-165.168 220.062,-155.021 211.353,-161.054 217.016,-165.168\"/>\n<text text-anchor=\"middle\" x=\"223.973\" y=\"-176.013\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\"><title>2</title>\n<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M72.5,-36C72.5,-36 42.5,-36 42.5,-36 36.5,-36 30.5,-30 30.5,-24 30.5,-24 30.5,-12 30.5,-12 30.5,-6 36.5,-0 42.5,-0 42.5,-0 72.5,-0 72.5,-0 78.5,-0 84.5,-6 84.5,-12 84.5,-12 84.5,-24 84.5,-24 84.5,-30 78.5,-36 72.5,-36\"/>\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M70.4788,-71.7615C68.3577,-63.1387 66.1683,-54.2385 64.2058,-46.2606\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"67.5689,-45.2796 61.7815,-36.4051 60.7715,-46.9517 67.5689,-45.2796\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\"><title>3</title>\n<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M144.5,-36C144.5,-36 114.5,-36 114.5,-36 108.5,-36 102.5,-30 102.5,-24 102.5,-24 102.5,-12 102.5,-12 102.5,-6 108.5,-0 114.5,-0 114.5,-0 144.5,-0 144.5,-0 150.5,-0 156.5,-6 156.5,-12 156.5,-12 156.5,-24 156.5,-24 156.5,-30 150.5,-36 144.5,-36\"/>\n<text text-anchor=\"middle\" x=\"129.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M101.85,-71.7615C106.521,-62.8481 111.347,-53.6382 115.635,-45.4571\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"118.837,-46.8872 120.379,-36.4051 112.637,-43.6378 118.837,-46.8872\"/>\n</g>\n<!-- 11 -->\n<g id=\"node6\" class=\"node\"><title>11</title>\n<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M240.5,-36C240.5,-36 210.5,-36 210.5,-36 204.5,-36 198.5,-30 198.5,-24 198.5,-24 198.5,-12 198.5,-12 198.5,-6 204.5,-0 210.5,-0 210.5,-0 240.5,-0 240.5,-0 246.5,-0 252.5,-6 252.5,-12 252.5,-12 252.5,-24 252.5,-24 252.5,-30 246.5,-36 240.5,-36\"/>\n<text text-anchor=\"middle\" x=\"225.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge5\" class=\"edge\"><title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M239.043,-71.7615C236.83,-63.1387 234.545,-54.2385 232.497,-46.2606\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"235.844,-45.2209 229.968,-36.4051 229.064,-46.9613 235.844,-45.2209\"/>\n</g>\n<!-- 18 -->\n<g id=\"node7\" class=\"node\"><title>18</title>\n<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M312.5,-36C312.5,-36 282.5,-36 282.5,-36 276.5,-36 270.5,-30 270.5,-24 270.5,-24 270.5,-12 270.5,-12 270.5,-6 276.5,-0 282.5,-0 282.5,-0 312.5,-0 312.5,-0 318.5,-0 324.5,-6 324.5,-12 324.5,-12 324.5,-24 324.5,-24 324.5,-30 318.5,-36 312.5,-36\"/>\n<text text-anchor=\"middle\" x=\"297.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\n</g>\n<!-- 10&#45;&gt;18 -->\n<g id=\"edge6\" class=\"edge\"><title>10&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M270.414,-71.7615C274.99,-62.8481 279.718,-53.6382 283.918,-45.4571\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"287.111,-46.8998 288.565,-36.4051 280.884,-43.7028 287.111,-46.8998\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "CumutApe6SdZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model on the validation data set\n",
        "\n",
        "For now, we will use the model to predict the binary classes of our validation data.  \n",
        "Later we'll look at the case where our model outputs a probability over class labels."
      ]
    },
    {
      "metadata": {
        "id": "GtJigb1SuTRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c47b6f3d-1021-4f40-95dd-e580c2317efa"
      },
      "cell_type": "code",
      "source": [
        "# make class predictions for the training validation set\n",
        "y_val_predict = model.predict(X_val)\n",
        "y_train_predict = model.predict(X_train)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WuOp6VQ4wq9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74bf5c0d-c5cb-466d-9f5e-c44c6e41c075"
      },
      "cell_type": "code",
      "source": [
        "# calculate model training accuracy\n",
        "from sklearn import metrics\n",
        "print('Training Accuracy:   {:01.3f}'.format(metrics.accuracy_score(y_train, y_train_predict)))\n",
        "\n",
        "# calculate model validation accuracy\n",
        "print('Validation Accuracy: {:01.3f}'.format(metrics.accuracy_score(y_val, y_val_predict)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy:   0.806\n",
            "Validation Accuracy: 0.778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_NEuINphjha5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that our **training accuracy** is higher than our **validation accuracy**.  This is fairly typical, as  machine learning algorithms have a tendency to overfit the training data.  When choosing a model, it's a good idea to tune it such that you are not overfitting too much.\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/fittings.jpg\" width=\"600\">"
      ]
    },
    {
      "metadata": {
        "id": "xLEkVGUX1XJY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Okay, so our decision tree got ~78% validation accuracy.  But how do we know if that's a \"good\" accuracy?  Let's look at the simple case where we have a model that always predicts the most common class.  How well would that do?"
      ]
    },
    {
      "metadata": {
        "id": "I3dLk7Gozt6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the class distribution of the validation set (using a Pandas Series method)\n",
        "y_val.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ollw--0a0FuN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This means that a trivial model that always predicts 0 would be right ~62% of the time.  So our decision tree seems to be doing something.\n",
        "\n",
        "Now let's investigate the errors our model is making by looking at the confusion matrix:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/confusion matrix 2.png\" width=\"250\">"
      ]
    },
    {
      "metadata": {
        "id": "Qw3xcAK3z5t-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use sklearn to make the confusion matrix\n",
        "print('Confusion Matrix:')\n",
        "labels = [0,1]\n",
        "cm = metrics.confusion_matrix(y_val, y_val_predict, labels)\n",
        "print(cm)\n",
        "\n",
        "# Normalized confusion matrix\n",
        "print('\\nNormalized Confusion Matrix:')\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "print(cm_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVNTxWYB1obX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Or you can use pandas -- it's a little nicer to look at\n",
        "pd.crosstab(y_val, y_val_predict, rownames=['True'], colnames=['Predicted'], margins=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UXUOndg_1lGf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize the confusion matrix\n",
        "def plot_cmatrix(cm,labels,title='Confusion Matrix'):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  cax = ax.matshow(cm,cmap='Reds')\n",
        "  plt.title('\\n'+title+'\\n', fontsize=20)\n",
        "  fig.colorbar(cax)\n",
        "  ax.set_xticklabels([''] + labels, fontsize=16)\n",
        "  ax.set_yticklabels([''] + labels, fontsize=16)\n",
        "  plt.xlabel('Predicted', fontsize=16)\n",
        "  plt.ylabel('True', fontsize=16)\n",
        "  plt.show()\n",
        "  \n",
        "plot_cmatrix(cm,labels)\n",
        "plot_cmatrix(cm_norm,labels,title='Normalized Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hczAcaUe4YP6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can even make a confusion matrix for the multi-class problem!  Check out this toy example:"
      ]
    },
    {
      "metadata": {
        "id": "w2f3hsH04YiW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y2=pd.Series(['dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'frog', 'dog', 'dog', 'cat', 'frog'])\n",
        "y2pred=pd.Series(['dog', 'cat', 'dog', 'dog', 'cat', 'frog', 'cat', 'cat', 'dog', 'cat', 'dog', 'frog', 'frog', 'dog', 'cat', 'frog'])\n",
        "\n",
        "animal_labels=['cat','dog','frog']\n",
        "cm = metrics.confusion_matrix(y2,y2pred, animal_labels)\n",
        "plot_cmatrix(cm,animal_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Fkg_EdKahkl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### More Metrics\n",
        "There are several useful metrics that are derived from the confusion matrix:\n",
        "* sensitivity, **recall**, hit rate, or true positive rate (TPR) : $ \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{P}}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}$\n",
        " \n",
        "* **precision** or positive predictive value (PPV) : $ \\mathrm {PPV} ={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FP} }}$\n",
        "\n",
        "* specificity or true negative rate (TNR) : $\\mathrm {TNR} ={\\frac {\\mathrm {TN} }{N}}={\\frac {\\mathrm {TN} }{\\mathrm {TN} +\\mathrm {FP} }}$\n",
        "\n",
        "* miss rate or false negative rate (FNR) : $ \\mathrm {FNR} ={\\frac {\\mathrm {FN} }{P}}={\\frac {\\mathrm {FN} }{\\mathrm {FN} +\\mathrm {TP} }}=1-\\mathrm {TPR}$\n",
        "\n",
        "* fall-out or false positive rate (FPR) : $\\mathrm {FPR} ={\\frac {\\mathrm {FP} }{N}}={\\frac {\\mathrm {FP} }{\\mathrm {FP} +\\mathrm {TN} }}=1-\\mathrm {TNR} $\n",
        "\n",
        "* accuracy (ACC) : $\\mathrm {ACC} ={\\frac {\\mathrm {TP} +\\mathrm {TN} }{P+N}}={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {TP} +\\mathrm {TN} +\\mathrm {FP} +\\mathrm {FN} }}$\n",
        "\n",
        "The F1 score is the harmonic mean of precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
        " * F1 score: $F_{1}=2\\cdot {\\frac {\\mathrm {PPV} \\cdot \\mathrm {TPR} }{\\mathrm {PPV} +\\mathrm {TPR} }}={\\frac {2\\mathrm {TP} }{2\\mathrm {TP} +\\mathrm {FP} +\\mathrm {FN} }}$\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iLRgnLA11eT-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Precision: {:01.3f}'.format(metrics.precision_score(y_val,y_val_predict)))\n",
        "print('Recall:    {:01.3f}'.format(metrics.accuracy_score(y_val,y_val_predict)))\n",
        "print('F1 score:  {:01.3f}'.format(metrics.f1_score(y_val,y_val_predict)))\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fY2Bf6446CT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model on the validation data set (part 2)\n",
        "\n",
        "Up to now, we've simply been evaluating our model's ability to predict the correct class.  But in many (most) cases, our model actually outputs a *probability* or *certainty* over the class labels.  Let's take a look at the output of our decision tree."
      ]
    },
    {
      "metadata": {
        "id": "nzlcegvR1a35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Predict class label probabilities\n",
        "labels = [0,1]\n",
        "y_val_prob = model.predict_proba(X_val,labels)\n",
        "\n",
        "# Output predicted and true values for the first validation point\n",
        "print('Probabilities:\\n',y_val_prob[0])\n",
        "print('\\nTrue Value:\\n',y_val.values[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0_TqOn0Bh53",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that the decision tree predicts that there is a ~87% probability that this data point belongs to class label 1.  But this doesn't necessarily mean we *have* to label the data point as class 1.  For example, we may decide to say that we need to be 90% confident that the data belongs to class 1, otherwise we say it belongs to class 0.  The predicted class will depend on where we threshold our decision boundary.  \n",
        "\n",
        "\n",
        "Choosing a threshold is not always as straighforward as choosing the label with the greatest probability.  Particularly in cases where your data set is very biased or there is a greater penalty for false positives than false negatives (and vice-versa), it is often desirable to evaluate the model over all thresholds.  This is where the **Receiver Operating Characteristic (ROC) curve** comes in!\n",
        "\n",
        "\n",
        "The ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.  The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
        "\n",
        "\n",
        "The **area under the curve (AUC) ** is often used as a more robust and descriptive metric of a classification model's performance, where an AUC of 1 is \"perfect\" and an AUC of 0 means that the classifier is no better than random."
      ]
    },
    {
      "metadata": {
        "id": "1oLYVkqEyWIr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Calculate the FPR and TPR at varying thresholds (assume label 1 is the \"postive\" class)\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_prob[:,1])\n",
        "\n",
        "# Calculate the area under the ROC curve\n",
        "roc_auc = metrics.auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anbcgur8ypbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(6,6))\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gk4nnCIYgXMX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Some additional exercises to do on your own:\n",
        "* Perform the same analysis above using [k-fold cross validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
        "* Choose a \"good\" threshold for your decision tree (according to some metric, e.g., minimizing False Positives)\n",
        "* Evaluate the TEST data using the model at your chosen threshold -- how does your classifier perform?"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}